"""
Dirichlet ê¸°ë°˜ Non-IID ë°ì´í„° ë¶„í•  + Stratified Train/Test Split
- PathMNISTì˜ Train ë°ì´í„°(89,958ê°œ)ë§Œ ì‚¬ìš©
- ê° í´ë¼ì´ì–¸íŠ¸ì— Dirichletìœ¼ë¡œ ë°ì´í„° ë¶„ë°°
- í´ë¼ì´ì–¸íŠ¸ ë‚´ì—ì„œ Stratified Splitìœ¼ë¡œ Train/Test ë¹„ìœ¨ ìœ ì§€
"""

import torch
from torch.utils.data import Subset
import torchvision.transforms as transforms
import numpy as np
import medmnist
from medmnist.info import INFO
import os
from sklearn.model_selection import train_test_split

# PathMNIST í´ë˜ìŠ¤ ì´ë¦„
CLASS_NAMES = [
    'ADI (Adipose)',
    'BACK (Background)', 
    'DEB (Debris)',
    'LYM (Lymphocytes)',
    'MUC (Mucus)',
    'MUS (Smooth Muscle)',
    'NORM (Normal Mucosa)',
    'STR (Stroma)',
    'TUM (Tumor)'
]

def dirichlet_split_noniid(labels, num_clients, num_classes, alpha, seed=42):
    """
    Dirichlet Distribution ê¸°ë°˜ Non-IID ë°ì´í„° ë¶„í• 
    """
    np.random.seed(seed)
    
    # í´ë˜ìŠ¤ë³„ë¡œ ë°ì´í„° ì¸ë±ìŠ¤ ê·¸ë£¹í™”
    class_indices = [np.where(labels == i)[0] for i in range(num_classes)]
    
    # ê° í´ë¼ì´ì–¸íŠ¸ê°€ ë°›ì„ ì¸ë±ìŠ¤ ì €ì¥ì†Œ ì´ˆê¸°í™”
    client_indices = [[] for _ in range(num_clients)]
    
    # ê° í´ë˜ìŠ¤ë¥¼ Dirichlet ë¶„í¬ë¡œ í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œ ë¶„ë°°
    for c_idx, c_indices in enumerate(class_indices):
        np.random.shuffle(c_indices)
        
        # Dirichlet ë¶„í¬ë¡œ ë¹„ìœ¨ ìƒì„±
        proportions = np.random.dirichlet(np.repeat(alpha, num_clients))
        
        # ë¹„ìœ¨ì„ ì‹¤ì œ ë°ì´í„° ê°œìˆ˜ë¡œ ë³€í™˜
        proportions = (np.cumsum(proportions) * len(c_indices)).astype(int)[:-1]
        
        # ì‹¤ì œë¡œ ë°ì´í„° ë¶„í• 
        split_indices = np.split(c_indices, proportions)
        
        # ê° í´ë¼ì´ì–¸íŠ¸ì—ê²Œ í• ë‹¹
        for client_id, indices in enumerate(split_indices):
            client_indices[client_id].extend(indices.tolist())
    
    # ê° í´ë¼ì´ì–¸íŠ¸ ë‚´ì—ì„œ ë°ì´í„° ì„ê¸°
    for client_id in range(num_clients):
        np.random.shuffle(client_indices[client_id])
    
    return client_indices


def stratified_train_test_split(dataset, indices, test_ratio=0.2, seed=42):
    """
    Stratified Train/Test ë¶„í•  - í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
    """
    # í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ë¼ë²¨ ì¶”ì¶œ
    labels = []
    for idx in indices:
        _, label = dataset[idx]
        if isinstance(label, torch.Tensor):
            labels.append(label.item())
        elif isinstance(label, np.ndarray):
            labels.append(label.item())
        else:
            labels.append(int(label))
    
    labels = np.array(labels)
    indices = np.array(indices)
    
    try:
        # Stratified split ì‹œë„
        train_idx, test_idx = train_test_split(
            indices, 
            test_size=test_ratio,
            stratify=labels,
            random_state=seed
        )
    except ValueError as e:
        # Stratified split ì‹¤íŒ¨ ì‹œ (í´ë˜ìŠ¤ë‹¹ ìƒ˜í”Œ ë¶€ì¡±)
        print(f"  âš ï¸ Stratified split ì‹¤íŒ¨, random split ì‚¬ìš©: {e}")
        train_idx, test_idx = train_test_split(
            indices,
            test_size=test_ratio,
            random_state=seed
        )
    
    return train_idx.tolist(), test_idx.tolist()


def analyze_distribution(dataset, indices, name=""):
    """í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ ë° ì¶œë ¥"""
    labels = []
    for idx in indices:
        _, label = dataset[idx]
        if isinstance(label, torch.Tensor):
            labels.append(label.item())
        elif isinstance(label, np.ndarray):
            labels.append(label.item())
        else:
            labels.append(int(label))
    
    labels = np.array(labels)
    
    print(f"\ní´ë˜ìŠ¤ ë¶„í¬ ({name}):")
    print(f"  {'í´ë˜ìŠ¤':<10} {'ìƒ˜í”Œ ìˆ˜':>10} {'ë¹„ìœ¨':>10} {'ì‹œê°í™”':<30}")
    print(f"  {'-'*60}")
    
    total = len(labels)
    for i in range(9):  # PathMNIST 9ê°œ í´ë˜ìŠ¤
        count = np.sum(labels == i)
        ratio = count / total * 100 if total > 0 else 0
        bar = 'â–ˆ' * int(ratio / 2)
        print(f"  {i:<10} {count:>10} {ratio:>9.1f}% {bar}")
    
    return labels


def create_client_data(num_clients=3, alpha=0.5, test_ratio=0.2, seed=42):
    """
    í´ë¼ì´ì–¸íŠ¸ë³„ ë°ì´í„° ìƒì„± (Stratified Split ì ìš©)
    """
    print("="*60)
    print("Dirichlet Non-IID ë°ì´í„° ë¶„í•  (Stratified Train/Test)")
    print("="*60)
    print(f"  í´ë¼ì´ì–¸íŠ¸ ìˆ˜: {num_clients}")
    print(f"  Alpha: {alpha}")
    print(f"  Test ë¹„ìœ¨: {test_ratio}")
    print(f"  Seed: {seed}")
    print("="*60)
    
    # ë°ì´í„° ë³€í™˜
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])
    
    # PathMNIST Train ë°ì´í„°ë§Œ ë¡œë“œ
    info = INFO['pathmnist']
    DataClass = getattr(medmnist, info['python_class'])
    
    train_dataset = DataClass(split='train', transform=transform, download=True)
    
    print(f"\nğŸ“Š PathMNIST Train ë°ì´í„°: {len(train_dataset)}ê°œ")
    
    # ì „ì²´ ë¼ë²¨ ì¶”ì¶œ
    all_labels = []
    for i in range(len(train_dataset)):
        _, label = train_dataset[i]
        if isinstance(label, torch.Tensor):
            all_labels.append(label.item())
        elif isinstance(label, np.ndarray):
            all_labels.append(label.item())
        else:
            all_labels.append(int(label))
    
    all_labels = np.array(all_labels)
    
    # ì „ì²´ í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥
    print("\nğŸ“Š ì „ì²´ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:")
    unique, counts = np.unique(all_labels, return_counts=True)
    for cls, cnt in zip(unique, counts):
        print(f"  Class {cls} ({CLASS_NAMES[cls]}): {cnt}ê°œ ({cnt/len(all_labels)*100:.1f}%)")
    
    # Dirichlet ë¶„í• 
    print("\n" + "="*60)
    print("ğŸ“¦ Dirichlet ë¶„í¬ë¡œ í´ë¼ì´ì–¸íŠ¸ë³„ ë°ì´í„° ë¶„í• ...")
    print("="*60)
    
    client_indices = dirichlet_split_noniid(
        all_labels, 
        num_clients=num_clients,
        num_classes=9,
        alpha=alpha,
        seed=seed
    )
    
    # ê° í´ë¼ì´ì–¸íŠ¸ë³„ ì²˜ë¦¬
    client_names = ['Pi5 8GB', 'Pi5 4GB', 'Pi4B 2GB']
    
    for client_id in range(num_clients):
        print("\n" + "="*60)
        print(f"í´ë¼ì´ì–¸íŠ¸ {client_id} ({client_names[client_id]}) ë°ì´í„° ì²˜ë¦¬")
        print("="*60)
        
        indices = client_indices[client_id]
        total_samples = len(indices)
        
        print(f"\ní• ë‹¹ëœ ì „ì²´ ë°ì´í„°: {total_samples}ê°œ")
        
        # ì „ì²´ ë¶„í¬ í™•ì¸
        client_labels = analyze_distribution(train_dataset, indices, "ì „ì²´")
        
        # Stratified Train/Test ë¶„í• 
        print(f"\nğŸ”€ Stratified Train/Test ë¶„í•  (ë¹„ìœ¨: {1-test_ratio:.0%}/{test_ratio:.0%})...")
        
        train_indices, test_indices = stratified_train_test_split(
            train_dataset, 
            indices, 
            test_ratio=test_ratio,
            seed=seed
        )
        
        print(f"  - Train: {len(train_indices)}ê°œ ({len(train_indices)/total_samples*100:.1f}%)")
        print(f"  - Test: {len(test_indices)}ê°œ ({len(test_indices)/total_samples*100:.1f}%)")
        
        # Train ë¶„í¬ í™•ì¸
        train_labels = analyze_distribution(train_dataset, train_indices, "Train")
        
        # Test ë¶„í¬ í™•ì¸
        test_labels = analyze_distribution(train_dataset, test_indices, "Test")
        
        # ë¶„í¬ ì¼ì¹˜ ê²€ì¦
        print("\nâœ… Train/Test ë¶„í¬ ë¹„êµ:")
        print(f"  {'í´ë˜ìŠ¤':<10} {'Train %':>10} {'Test %':>10} {'ì°¨ì´':>10}")
        print(f"  {'-'*45}")
        
        for i in range(9):
            train_ratio = np.sum(train_labels == i) / len(train_labels) * 100 if len(train_labels) > 0 else 0
            test_ratio_val = np.sum(test_labels == i) / len(test_labels) * 100 if len(test_labels) > 0 else 0
            diff = abs(train_ratio - test_ratio_val)
            status = "âœ“" if diff < 3 else "âš ï¸"
            print(f"  {i:<10} {train_ratio:>9.1f}% {test_ratio_val:>9.1f}% {diff:>8.1f}% {status}")
        
        # Subset ìƒì„±
        train_subset = Subset(train_dataset, train_indices)
        test_subset = Subset(train_dataset, test_indices)
        
        # ì €ì¥
        save_data = {
            'train': train_subset,
            'val': test_subset,  # ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ 'val' í‚¤ ì‚¬ìš©
            'num_classes': 9,
            'train_indices': train_indices,
            'test_indices': test_indices,
            'alpha': alpha,
            'client_id': client_id
        }
        
        filename = f'client_{client_id}_data.pt'
        torch.save(save_data, filename)
        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}")
    
    print("\n" + "="*60)
    print("âœ… ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    print("="*60)
    
    # ìµœì¢… ìš”ì•½
    print("\nğŸ“‹ ìµœì¢… ìš”ì•½:")
    print(f"{'Client':<15} {'Total':>10} {'Train':>10} {'Test':>10}")
    print("-"*50)
    
    total_all = 0
    for client_id in range(num_clients):
        data = torch.load(f'client_{client_id}_data.pt', weights_only=False)
        train_len = len(data['train'])
        test_len = len(data['val'])
        total_len = train_len + test_len
        total_all += total_len
        print(f"Client {client_id:<8} {total_len:>10} {train_len:>10} {test_len:>10}")
    
    print("-"*50)
    print(f"{'Total':<15} {total_all:>10}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Non-IID ë°ì´í„° ë¶„í•  (Stratified)')
    parser.add_argument('--num_clients', type=int, default=3, help='í´ë¼ì´ì–¸íŠ¸ ìˆ˜')
    parser.add_argument('--alpha', type=float, default=0.5, help='Dirichlet alpha')
    parser.add_argument('--test_ratio', type=float, default=0.2, help='í…ŒìŠ¤íŠ¸ ë¹„ìœ¨')
    parser.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ')
    
    args = parser.parse_args()
    
    create_client_data(
        num_clients=args.num_clients,
        alpha=args.alpha,
        test_ratio=args.test_ratio,
        seed=args.seed
    )